## ---------------------------------------------------------------------------
## Project settings
## ---------------------------------------------------------------------------

PROJECT_NAME=local-quantization
ENV=dev

## Execution profile: cpu | gpu
PROFILE=gpu

## ---------------------------------------------------------------------------
## Pipeline settings
## ---------------------------------------------------------------------------

## quantize | export | benchmark | full
PIPELINE_MODE=full

## ---------------------------------------------------------------------------
## Model settings
## ---------------------------------------------------------------------------

## Hugging Face repo id or local path
MODEL_NAME_OR_PATH=mistralai/Mistral-7B-Instruct-v0.3

## Optional HF revision or branch
MODEL_REVISION=

## Optional LoRA adapter path
ADAPTER_PATH=

## ---------------------------------------------------------------------------
## Quantization settings (COMMON)
## ---------------------------------------------------------------------------

## gguf | awq | gptq | bnb_nf4 | onnx
QUANT_BACKEND=awq

## Target bit-width (backend dependent)
QUANT_BITS=4

## Optional group size (GPTQ / AWQ)
QUANT_GROUP_SIZE=128

## Calibration dataset (optional but recommended for awq/gptq/onnx)
CALIBRATION_DATASET=./data/calibration.txt

## ---------------------------------------------------------------------------
## Export settings
## ---------------------------------------------------------------------------

EXPORT_OUTPUT_DIR=./artifacts/exports
EXPORT_OVERWRITE=false

## ---------------------------------------------------------------------------
## Benchmark settings
## ---------------------------------------------------------------------------

BENCHMARK_PROMPTS=./data/bench_prompts.txt
BENCHMARK_MAX_TOKENS=256
BENCHMARK_RUNS=5

## ---------------------------------------------------------------------------
## Logging settings
## ---------------------------------------------------------------------------

LOCAL_QUANTIZATION_LOG_LEVEL=INFO
LOCAL_QUANTIZATION_LOG_TO_FILE=true
LOCAL_QUANTIZATION_LOG_MAX_BYTES=10485760
LOCAL_QUANTIZATION_LOG_BACKUP_COUNT=5
